# ü¶ø Deep learning approaches to create generative models of lower limb sockets

> Companion repository of the paper _"The Effect of Augmentation and Transfer Learning on the Modelling of Lower-limb Sockets using 3D Adversarial Autoencoders"_, submited for review to the [Special Issue "Generative Models in Artificial Intelligence and Their Applications"](https://www.mdpi.com/journal/applsci/special_issues/Generative_Models_Applications) of [Applied Sciences](https://www.mdpi.com/journal/applsci) (ISSN 2076-3417; CODEN: ASPCC7).

This repository contains a **script and instructions on how to train an Adversarial Autoencoder on a custom dataset of 3D (`x`, `y`, `z`) data** (following the training schema described in the companion paper) **as well as weights obtained during pre-training on the ModelNet dataset**, useful for transfer learning. The socket-specific augmented dataset used throughout the paper is also [available in another repository](https://github.com/adapttech-ltd/SocketSSM).

![system_schema](figures/aae.png?raw=true)

## üöÖ Transfer learning based on ModelNet

A similar training scheme to what's described in the paper can be applied on custom 3D data (if pre-processed in the same way) taking advantage of the pre-trained weights of our model in the [ModelNet40](https://modelnet.cs.princeton.edu/) dataset (encoder, decoder and discriminator weights available in the _Releases_ tab of the repository). As described in the paper, these weights were obtained after training for 1500 epochs and extracting the epoch with the best Jensen‚ÄìShannon divergence measure (epoch 350). The model was trained using learning rates of `2.0e-4`, `5.0e-5` and `2.5e-5` for the reconstructor, generator and discriminator networks, respectively. To train on custom data: 

### Environment

Most of the heavy lifting of the repository is implemented using TensorFlow 2.0 in Python 3.7. A [full Conda environment spec](https://docs.conda.io/en/latest/) is provided in `environment.yaml` and can be configured with the following set of terminal commands: 

```bash
cd deep-generative-model #TODO Change
conda env create -f environment.yml
conda activate socket-aae
``` 

### Data pre-processing
Input shapes should be sampled to 2048 points and normalized to the unit sphere. Normalization can be performed online during training, by passing the appropriate argument to the training script. 

It is possible to resample and pre-process a dataset by using the `experiment.resample` module, whose full list of arguments is available when running `python -m experiment.resample --help`. 

For best results, input files should be meshes (`.obj` or `.off`). The output will be saved as .npy point clouds, following the same folder structure as the input dataset.

### Model Training
`aae.py` script performs an end-to-end training of a 3D Adversarial Autoencoder with custom datasets. A description of all its input arguments can be accessed by calling `python -m experiment.aae --help`

To use a custom dataset as input, the `.np·ª≥` files should be stored in a single folder, and its path passed to the training script using the `--dataset path` argument.

The input arguments include the option to perform transfer learning by loading previously trained weights. To use the weights from ModelNet pre-training available in the _Releases_ tab of this respository, unzip the folder anywhere on your computer and pass the folder path to the training script using the `--load weights_from` argument.

During training, the best model weights will be saved as measured by the improvement of Jensen‚ÄìShannon Divergence on the validation set (exact data split can be configured using the `--data_split` argument).

### Model Evaluation
`load model.py` script loads the weights of a previously trained model and evaluates its performance. A description of all its input arguments can be accessed by calling `python -m experiment.load_model --help`.

The evaluation consists of both reconstructive (Chamfer Distance) and generative metrics (Fidelity and Coverage). These metrics are complemented by the generation of relevant visualizations:

- shapes generated by random sampling.
- shapes generated by interpolation in the latent space.
- shape reconstruction.

## ‚ñ∂Ô∏è Applications
The generatives models trained using this code have multiple applications. One of them is the creation of a wide range of plausible shapes. This can be done:

- randomly, through the sampling of the encoded distribution.
- with purpose, by embedding in the shape specific characteristics through the use of techniques such as latent space interpolation/arithmetics. 
 
For examples and discussion of these applications, refer to the companion paper.

## üôè Acknowledgments
- Luis R. Gonzales, whose [`pointnet_own`](https://github.com/luis-gonzales/pointnet_own) was used as the base TensorFlow 2.0 implementation of the PointNet network. 
- `Mind-the-Pineapple`'s implementation of adversarial autoencoders in TensorFlow 2.0, at [`adversarial-autoencoder`](https://github.com/Mind-the-Pineapple/adversarial-autoencoder).
